
####################################################################
####################################################################
##############################  TRAIN  ##############################
####################################################################
####################################################################

############ ESTIMATION ############
declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn" "imagenet")
declare -a GroupMethod=("predicted_class" "score_equal_size")
declare -a MetricList=("groupwise_accuracy")
for metric in "${MetricList[@]}"
do
    for group_method in "${GroupMethod[@]}"
    do
        for dataset_name in "${DatasetNames[@]}"
        do
            python assess_accuracy.py --dataset_name $dataset_name \
                                      --group_method $group_method \
                                      --metric $metric \
                                      --pseudocount 2 \
                                      --topk 1&
        done
    done
done

declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn")
for dataset_name in "${DatasetNames[@]}"
do
    for run_start in {0..1000..100}
    do
        run_end=$((run_start+100))
        python assess_confusion_matrix.py --dataset_name $dataset_name --superclass False --run_start $run_start --run_end $run_end --pseudocount 1 --topk 1 &
    done
done

############ IDENTIFICATION ###############
declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn" "imagenet")
declare -a GroupMethod=("predicted_class")
declare -a MetricList=("least_accurate" "most_accurate")
for metric in "${MetricList[@]}"
do
    for group_method in "${GroupMethod[@]}"
    do
        for dataset_name in "${DatasetNames[@]}"
        do
            for topk in {1,3,10}
            do
                python assess_accuracy.py --dataset_name $dataset_name \
                                          --group_method $group_method \
                                          --metric $metric \
                                          --pseudocount 2 \
                                          --topk $topk&
            done
        done
    done
done

############ COMPARISON ###############
declare -a DatasetNames=("dbpedia" "20newsgroup" "svhn" "superclass_cifar100")
for dataset_name in "${DatasetNames[@]}"
do
    python assess_difference.py --dataset_name $dataset_name \
                              --group_method predicted_class \
                              --pseudocount 2&
done





####################################################################
####################################################################
##############################  EVAL  ##############################
####################################################################
####################################################################
declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn" "imagenet")
declare -a MetricList=("least_accurate" "most_accurate")
declare -a TopkList=("True" "False")
for dataset_name in "${DatasetNames[@]}"
do
    for metric in "${MetricList[@]}"
    do
        for topk in "${TopkList[@]}"
        do
            python eval_accuracy.py --dataset_name $dataset_name \
                                       --metric $metric \
                                       --group_method predicted_class \
                                       --pseudocount 2 \
                                       --topk $topk &
        done
    done
done



declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn" "imagenet")
declare -a GroupMethod=("score_equal_size" "predicted_class")
declare -a MetricList=("groupwise_accuracy")
for dataset_name in "${DatasetNames[@]}"
do
    for metric in "${MetricList[@]}"
    do
        for group_method in "${GroupMethod[@]}"
        do
            python eval_accuracy.py --dataset_name $dataset_name \
                                           --metric $metric \
                                           --group_method $group_method \
                                           --pseudocount 2 \
                                           --topk False &
        done
    done
done


declare -a DatasetNames=("cifar100" "dbpedia" "20newsgroup" "svhn")
for dataset_name in "${DatasetNames[@]}"
do
    python eval_confusion.py --dataset_name $dataset_name &
done



python eval_differnece.py