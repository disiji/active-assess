{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pathlib\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from data import Dataset, SuperclassDataset\n",
    "from data_utils import *\n",
    "from sampling import *\n",
    "from models import BetaBernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import mean_reciprocal_rank\n",
    "import pickle\n",
    "%matplotlib inline  \n",
    "\n",
    "import matplotlib;matplotlib.rcParams['font.size'] = 10\n",
    "import matplotlib;matplotlib.rcParams['font.family'] = 'serif'\n",
    "LINEWIDTH = 13.97\n",
    "\n",
    "LOG_FREQ = 10\n",
    "method_list = ['random_data', \n",
    "               'random_data_informed', \n",
    "               'ts_informed']\n",
    "DATASET_LIST = ['cifar100', 'svhn', '20newsgroup', 'dbpedia'] #'imagenet', \n",
    "output_dir = pathlib.Path(\"../output/confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'confusion_matrix' # 'ece', 'confusion_matrix'\n",
    "group_method = 'predicted_class'\n",
    "pseudocount = 1\n",
    "superclass = False #todo: superclass=true\n",
    "cost_matrix = None\n",
    "topk = 1\n",
    "\n",
    "# load results and compute ground truth\n",
    "ground_truth = {}\n",
    "weight_k = {}\n",
    "l2_error = {}\n",
    "logp = {} # log likelihood of each estimated confusion matrix under dirichlet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset_name in DATASET_LIST:\n",
    "    experiment_name = '%s_top%d_pseudocount%d' % (dataset_name, 1, 1)\n",
    "    ground_truth[dataset_name] = pickle.load(open(output_dir / experiment_name / \"ground_truth.pkl\", \"rb\"))  \n",
    "    l2_error[dataset_name] = pickle.load(open(output_dir / experiment_name / \"l2_error.pkl\", \"rb\"))  \n",
    "    logp[dataset_name] = pickle.load(open(output_dir / experiment_name / \"logp.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $L_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cifar100': {'random_data': array([[8.69496629e-01, 7.76317127e-01, 6.99477056e-01, ...,\n",
       "          9.78631614e-05, 9.78631616e-05, 9.78631618e-05],\n",
       "         [8.72564944e-01, 7.82952594e-01, 7.16014560e-01, ...,\n",
       "          9.78631613e-05, 9.78631616e-05, 9.78631618e-05],\n",
       "         [8.66230163e-01, 7.75034145e-01, 6.99876810e-01, ...,\n",
       "          9.78631614e-05, 9.78631616e-05, 9.78631618e-05],\n",
       "         ...,\n",
       "         [8.72861898e-01, 7.83447581e-01, 7.06310766e-01, ...,\n",
       "          9.78631613e-05, 9.78631616e-05, 9.78631618e-05],\n",
       "         [8.81477132e-01, 7.81270041e-01, 6.92449583e-01, ...,\n",
       "          9.78631613e-05, 9.78631616e-05, 9.78631618e-05],\n",
       "         [8.85535269e-01, 8.09982001e-01, 7.28588869e-01, ...,\n",
       "          9.78631614e-05, 9.78631616e-05, 9.78631618e-05]]),\n",
       "  'random_data_informed': array([[2.87049885e-02, 2.68342596e-02, 2.36369505e-02, ...,\n",
       "          6.97718351e-05, 6.97972218e-05, 6.98161472e-05],\n",
       "         [2.91856627e-02, 2.61121007e-02, 2.50647129e-02, ...,\n",
       "          6.97605630e-05, 6.97913967e-05, 6.98161472e-05],\n",
       "         [2.82025378e-02, 2.56712708e-02, 2.42393962e-02, ...,\n",
       "          6.97689034e-05, 6.97939456e-05, 6.98161472e-05],\n",
       "         ...,\n",
       "         [2.66298587e-02, 2.49194349e-02, 2.27596708e-02, ...,\n",
       "          6.97670218e-05, 6.97896935e-05, 6.98161472e-05],\n",
       "         [2.80962242e-02, 2.50649420e-02, 2.21148387e-02, ...,\n",
       "          6.97681070e-05, 6.97909800e-05, 6.98161472e-05],\n",
       "         [2.77854326e-02, 2.54716972e-02, 2.32977524e-02, ...,\n",
       "          6.97732035e-05, 6.97944827e-05, 6.98161472e-05]]),\n",
       "  'ts_informed': array([[2.38808373e-02, 1.94326347e-02, 1.59139008e-02, ...,\n",
       "          6.97985878e-05, 6.98077735e-05, 6.98161472e-05],\n",
       "         [2.41286237e-02, 1.93566494e-02, 1.57718969e-02, ...,\n",
       "          6.97985878e-05, 6.98077735e-05, 6.98161472e-05],\n",
       "         [2.38808373e-02, 1.93566494e-02, 1.57718969e-02, ...,\n",
       "          6.97984432e-05, 6.98077735e-05, 6.98161472e-05],\n",
       "         ...,\n",
       "         [2.39877518e-02, 1.95598929e-02, 1.58638576e-02, ...,\n",
       "          6.97984432e-05, 6.98080076e-05, 6.98161472e-05],\n",
       "         [2.42018671e-02, 1.91442987e-02, 1.59026108e-02, ...,\n",
       "          6.97984432e-05, 6.98077735e-05, 6.98161472e-05],\n",
       "         [2.38808373e-02, 1.91985713e-02, 1.58150824e-02, ...,\n",
       "          6.97984432e-05, 6.98080076e-05, 6.98161472e-05]]),\n",
       "  'diagonal': array(9.78633595e-05),\n",
       "  'ones': array(0.97049558),\n",
       "  'scores': array(0.08654822)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_error[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'random_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e347603a109f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2_error\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'random_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mstepsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmethod_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'random_data'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1005.84x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "method_format = {#'random_arm': ('Random Arm', 'g', '.', '--'), \n",
    "                 'random_data': ('Random', 'b', '^', '--'), \n",
    "                 #'random_arm_informed': ('Random Arm Informed', 'g', '.', '-'), \n",
    "                 'random_data_informed': ('Random Informed', 'b', '^', '-'), \n",
    "                 #'ts_uniform': ('TS Symmetric', 'k', '*', '-'), \n",
    "                 'ts_informed': ('TS Informed', 'r', '+', '-'),}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(DATASET_LIST), figsize=(LINEWIDTH,3),\n",
    "                        gridspec_kw = {'wspace':0.2, 'hspace':0.25})\n",
    "for i, dataset_name in enumerate(DATASET_LIST):\n",
    "    start = 0\n",
    "    num_steps = l2_error[dataset_name]['random_data'].shape[1] - 1\n",
    "    stepsize = 1\n",
    "    for method_name in method_format:\n",
    "        legend_name, color, marker, linestyle = method_format[method_name]    \n",
    "        xrange = np.arange(num_steps) * LOG_FREQ + LOG_FREQ\n",
    "        idx = np.arange(num_steps)[start:(start+num_steps)][::stepsize]   \n",
    "        axes[i].plot(xrange[idx], \n",
    "                 np.mean((l2_error[dataset_name][method_name]), axis=0)[idx], \n",
    "                 label=legend_name, linewidth=3, color=color, linestyle=linestyle)\n",
    "        axes[i].fill_between(xrange[idx], \n",
    "                         np.quantile(l2_error[dataset_name][method_name], 0.125, axis=0)[idx], \n",
    "                         np.quantile(l2_error[dataset_name][method_name], 0.875, axis=0)[idx], \n",
    "                         color=color, alpha=.2)\n",
    "        #plt.ylim([0, 0.3])\n",
    "    axes[i].set_xlabel('#Labeled')\n",
    "    axes[i].set_xscale('log')\n",
    "    axes[i].set_title(DATASET_NAMES[dataset_name])\n",
    "    axes[i].set_xlim(0,1000)\n",
    "    #axes[i].set_ylim(0,np.max(np.mean((l2_error[dataset_name]['random_data_informed']), axis=0)))\n",
    "axes[0].legend(fontsize=10, loc='upper right')\n",
    "axes[0].set_ylabel('$L_2$ Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_format = {'random_data': ('Random', 'b', '^', '--'), \n",
    "                 'random_data_informed': ('Random Informed', 'b', '^', '-'), \n",
    "                 'ts_informed': ('TS Informed', 'r', '+', '-'),}\n",
    "for i, dataset_name in enumerate(DATASET_LIST):\n",
    "    print('\\n',dataset_name)\n",
    "    dataset = Dataset.load_from_text(dataset_name)\n",
    "    dataset.group(group_method = group_method)\n",
    "    num_params = dataset.num_groups ^ 2\n",
    "    N_list = [20,50,100]\n",
    "    for N in N_list:\n",
    "        N = max(int(N//10)*10, 10)\n",
    "        print(\"N, #params=(%d,%d) =======\" % (N,num_params))\n",
    "        for method_name in method_format:\n",
    "            print('%s: %.4f' % (method_name, l2_error[dataset_name][method_name][:, (N-LOG_FREQ)//LOG_FREQ].mean() / \\\n",
    "                 l2_error[dataset_name]['scores']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_print= {\n",
    "    'cifar100': 'CIFAR-100',\n",
    "    'svhn': 'SVHN',\n",
    "    '20newsgroup': '20 Newsgroups',\n",
    "    'dbpedia': 'DBpedia'\n",
    "}\n",
    "dataset_list = ['cifar100','svhn', '20newsgroup','dbpedia']\n",
    "method_format = {'random_data': ('Random', 'b', '^', '--'), \n",
    "                 'random_data_informed': ('Random Informed', 'b', '^', '-'), \n",
    "                 'ts_informed': ('TS Informed', 'r', '+', '-'),}\n",
    "Nlist = [10,100,500];\n",
    "\n",
    "print('\\\\begin{tabular}{@{}ccccccccccccccccc@{}}')\n",
    "print('\\\\toprule ')\n",
    "for dataset in dataset_list:\n",
    "    print('& \\phantom{a} &  \\multicolumn{3}{c}{%s}' % dataset_print[dataset])\n",
    "print('\\\\\\ ')\n",
    "for dataset in dataset_list:\n",
    "    print('& \\phantom{a} &  N=%d & N=%d & N=%d' % tuple(Nlist))\n",
    "print('\\\\\\ ')\n",
    "print('\\cmidrule{3-5} \\cmidrule{7-9} \\cmidrule{11-13} \\cmidrule{15-17}')\n",
    "\n",
    "for method in method_format:\n",
    "    method_name = method_format[method][0]\n",
    "    print('\\multicolumn{2}{c}{%15s}' % method_name, end = '')\n",
    "    \n",
    "    for dataset_name in dataset_list:\n",
    "        for N in N_list:\n",
    "            val = l2_error[dataset_name][method][:, (N-LOG_FREQ)//LOG_FREQ].mean() / \\\n",
    "                        l2_error[dataset_name]['scores']\n",
    "            print('& %4.1f  ' % (100 * val), end = '')\n",
    "            \n",
    "        if dataset_name != dataset_list[-1]:\n",
    "            print('&', end = '')\n",
    "    print('\\\\\\\\ \\n', end = '');\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\end{tabular}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_print= {\n",
    "    'cifar100': 'CIFAR-100',\n",
    "    'svhn': 'SVHN',\n",
    "    '20newsgroup': '20 Newsgroups',\n",
    "    'dbpedia': 'DBpedia'\n",
    "}\n",
    "dataset_list = ['cifar100','svhn']\n",
    "#dataset_list = ['20newsgroup','dbpedia']\n",
    "method_format = {'random_data': ('Random Uninformative', 'b', '^', '--'), \n",
    "                 'random_data_informed': ('Random Informative', 'b', '^', '-'), \n",
    "                 'ts_informed': ('TS Informative', 'r', '+', '-'),}\n",
    "N_list = [20, 50, 100];\n",
    "\n",
    "print('\\\\begin{tabular}{@{}ccccccccc@{}}')\n",
    "print('\\\\toprule ')\n",
    "for dataset in dataset_list:\n",
    "    print('& \\phantom{a} &  \\multicolumn{3}{c}{%s}' % dataset_print[dataset])\n",
    "print('\\\\\\ ')\n",
    "print('\\cmidrule{3-5} \\cmidrule{7-9}')\n",
    "for dataset in dataset_list:\n",
    "    print('& \\phantom{a} &  N=%d & N=%d & N=%d' % tuple(Nlist))\n",
    "print('\\\\\\ \\\\midrule')\n",
    "\n",
    "for method in method_format:\n",
    "    method_name = method_format[method][0]\n",
    "    print('\\multicolumn{2}{c}{%20s}' % method_name, end = '')\n",
    "    \n",
    "    for dataset_name in dataset_list:\n",
    "        y = l2_error[dataset_name][method]/l2_error[dataset_name]['scores']\n",
    "        y = np.mean(y, axis=0)        \n",
    "        for N in N_list:\n",
    "            val = y[(N-LOG_FREQ)//LOG_FREQ]\n",
    "            print('& %.3f  ' % val, end = '')\n",
    "            \n",
    "        if dataset_name != dataset_list[-1]:\n",
    "            print('&', end = '')\n",
    "    print('\\\\\\\\ \\n', end = '');\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\end{tabular}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups_dict = {}\n",
    "for dataset in DATASET_LIST:\n",
    "    if group_method == 'score_equal_size':\n",
    "        num_groups_dict[dataset] = 10\n",
    "    if group_method == 'predicted_class':\n",
    "        num_groups_dict[dataset] = NUM_CLASSES_DICT[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_narrow_table(dataset_list):\n",
    "    \n",
    "    N_list = [2, 5, 6, 7, 8,9, 10]\n",
    "    method_format = {'random_data': ('UPrior', 'b', '^', '--'), \n",
    "                     #'ts_uniform': ('UPrior+TS', 'b', '^', '--'), \n",
    "                     'random_data_informed': ('IPrior', 'b', '^', '-'), \n",
    "                     'ts_informed': ('IPrior+TS', 'r', '+', '-'),}\n",
    "    print('\\\\begin{tabular}{@{}ccccccc@{}}')\n",
    "    print('\\\\toprule ')\n",
    "    print('{N/K} & {N}', end = '')\n",
    "    for method in method_format:\n",
    "        print('& {%10s}' % method_format[method][0], end = '')\n",
    "    print('\\\\\\ ')\n",
    "    \n",
    "    for i, dataset_name in enumerate(dataset_list):\n",
    "        print('\\\\midrule')\n",
    "        for idx, N in enumerate(N_list):\n",
    "            if idx == 0:\n",
    "                name_string = DATASET_NAMES[dataset_name]\n",
    "            else:\n",
    "                name_string = ''\n",
    "            vals = []\n",
    "            for method in method_format:\n",
    "                y = l2_error[dataset_name][method]/l2_error[dataset_name]['scores']\n",
    "                y = np.mean(y, axis=0) \n",
    "                K = num_groups_dict[dataset_name]\n",
    "                num_samples = int(N*K)\n",
    "                vals.append(y[(num_samples-LOG_FREQ)//LOG_FREQ])\n",
    "            print('{%20s} & %d & %d & %.3f &%.3f &\\\\textbf{%.3f} \\\\\\\\ \\n' % \\\n",
    "                  (name_string, N, num_samples, vals[0], vals[1], vals[2]), end = '')\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "\n",
    "print_narrow_table(DATASET_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in method_format:\n",
    "    method_name = method_format[method][0]\n",
    "    for dataset_name in dataset_list:\n",
    "        y = l2_error[dataset_name][method]/l2_error[dataset_name]['scores']\n",
    "        y = np.mean(y, axis=0)        \n",
    "        for N in N_list:\n",
    "            val = y[(N-LOG_FREQ)//LOG_FREQ]\n",
    "            print('====', method, dataset_name, (N-LOG_FREQ)//LOG_FREQ, val)\n",
    "        print(y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "method_format = {#'random_arm': ('Random Arm', 'g', '.', '--'), \n",
    "                 #'random_data': ('Random', 'b', '^', '--'), \n",
    "                 #'random_arm_informed': ('Random Arm Informed', 'g', '.', '-'), \n",
    "                 'random_data_informed': ('Random Informative', 'b', '^', '-'), \n",
    "                 #'ts_uniform': ('TS Symmetric', 'k', '*', '-'), \n",
    "                 'ts_informed': ('TS Informative', 'r', '+', '-'),}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(DATASET_LIST), figsize=(LINEWIDTH,2.2),\n",
    "                        gridspec_kw = {'wspace':0.2, 'hspace':0.25})\n",
    "for i, dataset_name in enumerate(DATASET_LIST):\n",
    "    start = 0\n",
    "    num_steps = l2_error[dataset_name]['ts_informed'].shape[1] - 1\n",
    "    stepsize = 1\n",
    "    for method_name in method_format:\n",
    "        legend_name, color, marker, linestyle = method_format[method_name]    \n",
    "        xrange = np.arange(num_steps) * LOG_FREQ + LOG_FREQ\n",
    "        idx = np.arange(num_steps)[start:(start+num_steps)][::stepsize]  \n",
    "        y = l2_error[dataset_name][method_name]/ l2_error[dataset_name]['scores']\n",
    "        eval_mean = np.mean(y, axis=0)\n",
    "        eval_upper = np.quantile(y, 0.875, axis=0)\n",
    "        eval_lower = np.quantile(y, 0.125, axis=0)\n",
    "        axes[i].plot(xrange[idx], \n",
    "                 eval_mean[idx], \n",
    "                 label=legend_name, linewidth=3, color=color, linestyle=linestyle)\n",
    "        axes[i].fill_between(xrange[idx], \n",
    "                         eval_lower[idx], \n",
    "                         eval_upper[idx], \n",
    "                         color=color, alpha=.2)\n",
    "        #plt.ylim([0, 0.3])\n",
    "    axes[i].set_xlabel('#Labeled')\n",
    "    axes[i].set_xscale('log')\n",
    "    #axes[i].set_yscale('log')\n",
    "    axes[i].set_title(DATASET_NAMES[dataset_name])\n",
    "axes[0].legend(fontsize=10, loc='upper right')\n",
    "axes[0].set_ylabel('$L_2$ Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error[dataset_name]['diagonal'], l2_error[dataset_name]['ones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(difference > 0).sum(), (difference < 0).sum(), difference.max(), difference.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "for i, dataset_name in enumerate(['dbpedia']):\n",
    "    for n in [2,5,10]:\n",
    "        for (method_0, method_1) in [#('random_data', 'random_data_informed'),\\\n",
    "                                     # ('random_data_informed', 'ts_informed'),\\\n",
    "                                    ('random_data', 'ts_informed')]:\n",
    "            num_samples = n * num_groups_dict[dataset_name]\n",
    "            difference = (np.array(l2_error[dataset_name][method_0][:,(num_samples-LOG_FREQ)//LOG_FREQ]) - \\\n",
    "                                np.array(l2_error[dataset_name][method_1][:,(num_samples-LOG_FREQ)//LOG_FREQ])) \\\n",
    "                                        / l2_error[dataset_name]['scores']\n",
    "            w, p = wilcoxon(difference)\n",
    "            print(p)\n",
    "            #print(difference)\n",
    "            if p > 0.0000001:\n",
    "                print(dataset_name, n, method_0, method_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
