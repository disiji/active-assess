{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import argparse\n",
    "from typing import Dict, Any\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from data_utils import DATASIZE_DICT, FIGURE_DIR, RESULTS_DIR\n",
    "from data_utils import DATASET_NAMES, TOPK_DICT\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "RUNS = 100\n",
    "LOG_FREQ = 100\n",
    "METHOD_NAME_DICT = {#'non-active_no_prior': 'Non-active',\n",
    "                    'non-active_uniform': 'non-active_uniform',\n",
    "                    'non-active_informed': 'non-active_informed',\n",
    "                    #'ts_uniform': 'TS',\n",
    "                    'ts_informed': 'TS (informative)',\n",
    "                    #'epsilon_greedy_no_prior': 'Epsilon greedy',\n",
    "                    #'bayesian_ucb_no_prior': 'Bayesian UCB',\n",
    "                    }\n",
    "COLUMN_WIDTH = 3.25  # Inches\n",
    "TEXT_WIDTH = 6.299213  # Inches\n",
    "GOLDEN_RATIO = 1.61803398875\n",
    "RESULTS_DIR = '../output/'\n",
    "dataset_names = TOPK_DICT.keys()\n",
    "group_method = 'predicted_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudocount = 2\n",
    "\n",
    "\n",
    "def compute(METRIC, MODE, TOPK, eval_metric):\n",
    "    \n",
    "    if METRIC == 'accuracy':\n",
    "        METHOD_NAME_LIST = ['random_arm', 'random_data', 'random_arm_informed', \\\n",
    "                            'random_data_informed', 'ts_uniform', 'ts_informed']\n",
    "        if MODE == 'min':\n",
    "            task = 'least_accurate/'\n",
    "        else:\n",
    "            task = 'most_accurate/'\n",
    "    elif METRIC == 'calibration_error':\n",
    "        METHOD_NAME_DICT = {'non-active': 'Non-active',\n",
    "                            'ts': 'TS'}\n",
    "        if MODE == 'min':\n",
    "            task = 'least_biased/'\n",
    "        else:\n",
    "            task = 'most_biased/'\n",
    "    counts = np.zeros((len(dataset_names), len(METHOD_NAME_LIST)))\n",
    "    for i, dataset_name in enumerate(dataset_names):\n",
    "        if TOPK:\n",
    "            topk = TOPK_DICT[dataset_name]\n",
    "        else:\n",
    "            topk = 1\n",
    "        experiment_name = '%s_groupby_%s_top%d_pseudocount%.2f/' % (dataset_name, group_method, topk, pseudocount)\n",
    "        mrr_dict = pickle.load(open(RESULTS_DIR + task + experiment_name + ('mrr.pkl'), \"rb\" ))\n",
    "        # method: num_runs, num_samples // LOG_FREQ\n",
    "        for j, method_name in enumerate(METHOD_NAME_LIST):\n",
    "            metric_eval = np.mean(mrr_dict[method_name], axis=1)\n",
    "            metric_eval = np.argmax(metric_eval > min(0.99, metric_eval.max()*0.99)) + 5\n",
    "            #metric_eval[metric_eval==0] = DATASIZE_DICT[dataset_name] / LOG_FREQ\n",
    "            counts[i][j] = int(metric_eval * LOG_FREQ + LOG_FREQ) * 1.0 / DATASIZE_DICT[dataset_name]\n",
    "    df = pd.DataFrame(np.round(counts.T*100, 1), \n",
    "                      index=METHOD_NAME_LIST, \n",
    "                      columns=dataset_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['accuracy_min_top1'] = compute('accuracy', 'min', False, 'mrr')\n",
    "results['accuracy_min_topm'] = compute('accuracy', 'min', True, 'mrr')\n",
    "# results['ece_max_top1'] = compute('calibration_error', 'max', False, 'mrr')\n",
    "# results['ece_max_topm'] = compute('calibration_error', 'max', True, 'mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{@{}rrrccccccccccccc@{}}\n",
      "\\toprule \n",
      "& \n",
      "& \\phantom{a} &  \\multicolumn{3}{c}{$ACC, Top 1$}\n",
      "& \\phantom{a} &  \\multicolumn{3}{c}{$ACC, Top m$}\n",
      "& \\phantom{a} &  \\multicolumn{2}{c}{$ECE, Top 1$}\n",
      "& \\phantom{a} &  \\multicolumn{2}{c}{$ECE, Top m$}\\\\ \n",
      "\\cmidrule{4-6} \\cmidrule{8-10} \\cmidrule{12-13} \\cmidrule{15-16}\n",
      "\\multicolumn{2}{c}{Dataset} && R  &RI &TSI  && R &RI &TSI && R &TS && R &TS \\\\ \\midrule\n",
      "\\multicolumn{2}{c}{     CIFAR-100}  &&816.0 &839.0 &254.0  &&1003.0 &1003.0 &556.0  &&254.0 &1003.0 &&1003.0 &556.0\\\\ \n",
      "\\multicolumn{2}{c}{      ImageNet}  &&970.0 &948.2 &94.4  &&997.2 &985.8 &172.2  &&94.4 &997.2 &&985.8 &172.2\\\\ \n",
      "\\multicolumn{2}{c}{          SVHN}  &&906.6 &900.0 &830.1  &&1001.8 &1001.5 &962.3  &&830.1 &1001.8 &&1001.5 &962.3\\\\ \n",
      "\\multicolumn{2}{c}{ 20 Newsgroups}  &&545.7 &560.3 &175.3  &&926.7 &932.0 &431.5  &&175.3 &926.7 &&932.0 &431.5\\\\ \n",
      "\\multicolumn{2}{c}{       DBpedia}  &&80.7 &76.3 &117.1  &&920.1 &902.3 &572.0  &&117.1 &920.1 &&902.3 &572.0\\\\ \n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "dataset_print= {\n",
    "    'cifar100': 'CIFAR-100',\n",
    "    'imagenet': 'ImageNet',\n",
    "    'svhn': 'SVHN',\n",
    "    '20newsgroup': '20 Newsgroups',\n",
    "    'dbpedia': 'DBpedia'\n",
    "}\n",
    "tasklist = ['accuracy_min_top1','accuracy_min_topm','ece_max_top1','ece_max_topm']\n",
    "\n",
    "print('\\\\begin{tabular}{@{}rrrccccccccccccc@{}}')\n",
    "print('\\\\toprule ')\n",
    "print('& ')\n",
    "print('& \\phantom{a} &  \\multicolumn{3}{c}{$ACC, Top 1$}')\n",
    "print('& \\phantom{a} &  \\multicolumn{3}{c}{$ACC, Top m$}')\n",
    "print('& \\phantom{a} &  \\multicolumn{2}{c}{$ECE, Top 1$}')\n",
    "print('& \\phantom{a} &  \\multicolumn{2}{c}{$ECE, Top m$}\\\\\\ ')\n",
    "print('\\cmidrule{4-6} \\cmidrule{8-10} \\cmidrule{12-13} \\cmidrule{15-16}')\n",
    "print('\\multicolumn{2}{c}{Dataset} && R  &RI &TSI  && R &RI &TSI && R &TS && R &TS \\\\\\ \\midrule')\n",
    "for i in dataset_print.keys():\n",
    "    print('\\multicolumn{2}{c}{%14s}  ' % dataset_print[i], end = '')\n",
    "    vals = (results['accuracy_min_top1'][i]['random_data'],\n",
    "            results['accuracy_min_top1'][i]['random_data_informed'],\n",
    "            results['accuracy_min_top1'][i]['ts_informed'],\n",
    "            results['accuracy_min_topm'][i]['random_data'],\n",
    "            results['accuracy_min_topm'][i]['random_data_informed'],\n",
    "            results['accuracy_min_topm'][i]['ts_informed'],\n",
    "#             results['ece_max_top1'][i]['non-active'],\n",
    "#             results['ece_max_top1'][i]['ts'],\n",
    "#             results['ece_max_topm'][i]['non-active'],\n",
    "#             results['ece_max_topm'][i]['ts'])\n",
    "            results['accuracy_min_top1'][i]['ts_informed'],\n",
    "            results['accuracy_min_topm'][i]['random_data'],\n",
    "            results['accuracy_min_topm'][i]['random_data_informed'],\n",
    "            results['accuracy_min_topm'][i]['ts_informed'])\n",
    "    print('&&%4.1f &%4.1f &%4.1f  &&%4.1f &%4.1f &%4.1f  &&%4.1f &%4.1f &&%4.1f &%4.1f\\\\' % vals, end = '')\n",
    "    print('\\\\ \\n', end = '');\n",
    "print('\\\\bottomrule')\n",
    "print('\\\\end{tabular}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
